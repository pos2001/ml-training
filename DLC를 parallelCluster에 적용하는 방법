
ParallelCluster + DLC í†µí•© ê°€ì´ë“œ

ì •í™•í•©ë‹ˆë‹¤! í•˜ì§€ë§Œ ë” ë‚˜ì€ ë°©ë²•ë“¤ì´ ìžˆìŠµë‹ˆë‹¤. DLC(AWS Deep Learning Containers)ë¥¼ ParallelClusterì— í†µí•©í•˜ëŠ” ì—¬ëŸ¬ ë°©ë²•ì„ ì•Œë ¤ë“œë¦¬ê² ìŠµë‹ˆë‹¤.
ðŸŽ¯ DLC í†µí•© ë°©ë²• ë¹„êµ
ë°©ë²•	ë‚œì´ë„	ì„±ëŠ¥	ìœ ì§€ë³´ìˆ˜	ê¶Œìž¥ë„
1. OnNodeConfigured ìŠ¤í¬ë¦½íŠ¸	â­â­	â­â­â­	â­â­	â­â­â­
2. Custom AMI	â­â­â­â­	â­â­â­â­â­	â­â­â­â­	â­â­â­â­â­
3. Enroot/Pyxis (DLC ë³€í™˜)	â­â­â­	â­â­â­â­â­	â­â­â­â­â­	â­â­â­â­â­
4. Docker ì§ì ‘ ì‚¬ìš©	â­	â­â­	â­	â­â­
ðŸ“¦ ë°©ë²• 1: OnNodeConfigured ìŠ¤í¬ë¦½íŠ¸ (ê°€ìž¥ ê°„ë‹¨)
ParallelCluster ì„¤ì •
# config.yaml
Region: us-east-1
Image:
  Os: alinux2

HeadNode:
  InstanceType: c5.4xlarge
  Networking:
    SubnetId: subnet-12345678
  Iam:
    AdditionalIamPolicies:
      - Policy: arn:aws:iam::aws:policy/AmazonEC2ContainerRegistryReadOnly
  CustomActions:
    OnNodeConfigured:
      Script: s3://my-bucket/scripts/setup_dlc_head.sh

Scheduling:
  Scheduler: slurm
  SlurmQueues:
    - Name: compute
      ComputeResources:
        - Name: gpu-nodes
          InstanceType: p4d.24xlarge
          MinCount: 0
          MaxCount: 100
          Efa:
            Enabled: true
      
      Networking:
        SubnetIds:
          - subnet-12345678
        PlacementGroup:
          Enabled: true
      
      # ì»´í“¨íŠ¸ ë…¸ë“œì—ì„œ DLC ì„¤ì¹˜
      CustomActions:
        OnNodeConfigured:
          Script: s3://my-bucket/scripts/setup_dlc_compute.sh
          Args:
            - pytorch
            - 2.1.0-gpu-py310-cu118-ubuntu20.04
      
      Iam:
        AdditionalIamPolicies:
          - Policy: arn:aws:iam::aws:policy/AmazonEC2ContainerRegistryReadOnly

SharedStorage:
  - MountDir: /fsx
    Name: fsx-storage
    StorageType: FsxLustre
    FsxLustreSettings:
      StorageCapacity: 1200

OnNodeConfigured ìŠ¤í¬ë¦½íŠ¸
#!/bin/bash
# scripts/setup_dlc_compute.sh
# S3ì— ì—…ë¡œë“œ: aws s3 cp setup_dlc_compute.sh s3://my-bucket/scripts/

set -e

# ì¸ìž ë°›ê¸°
DLC_FRAMEWORK=${1:-pytorch}  # pytorch, tensorflow, mxnet
DLC_VERSION=${2:-2.1.0-gpu-py310-cu118-ubuntu20.04}

echo "=== Setting up DLC on Compute Node ==="
echo "Framework: $DLC_FRAMEWORK"
echo "Version: $DLC_VERSION"

# 1. Docker ì„¤ì¹˜ (Amazon Linux 2)
if ! command -v docker &> /dev/null; then
    echo "Installing Docker..."
    sudo yum update -y
    sudo yum install -y docker
    sudo systemctl start docker
    sudo systemctl enable docker
    sudo usermod -aG docker ec2-user
fi

# 2. NVIDIA Container Toolkit ì„¤ì¹˜
if ! command -v nvidia-container-toolkit &> /dev/null; then
    echo "Installing NVIDIA Container Toolkit..."
    
    distribution=$(. /etc/os-release;echo $ID$VERSION_ID)
    curl -s -L https://nvidia.github.io/libnvidia-container/$distribution/libnvidia-container.repo | \
        sudo tee /etc/yum.repos.d/nvidia-container-toolkit.repo
    
    sudo yum install -y nvidia-container-toolkit
    sudo nvidia-ctk runtime configure --runtime=docker
    sudo systemctl restart docker
fi

# 3. ECR ë¡œê·¸ì¸
AWS_REGION=$(ec2-metadata --availability-zone | sed 's/placement: \(.*\).$/\1/')
AWS_ACCOUNT_ID=$(aws sts get-caller-identity --query Account --output text)

echo "Logging into ECR..."
aws ecr get-login-password --region $AWS_REGION | \
    docker login --username AWS --password-stdin \
    763104351884.dkr.ecr.$AWS_REGION.amazonaws.com

# 4. DLC ì´ë¯¸ì§€ Pull
DLC_IMAGE="763104351884.dkr.ecr.$AWS_REGION.amazonaws.com/$DLC_FRAMEWORK-training:$DLC_VERSION"
echo "Pulling DLC image: $DLC_IMAGE"
docker pull $DLC_IMAGE

# 5. Enroot ì„¤ì¹˜ (ì„ íƒì  - Slurm í†µí•©ìš©)
if ! command -v enroot &> /dev/null; then
    echo "Installing Enroot..."
    
    # Enroot ì„¤ì¹˜
    sudo yum install -y jq squashfs-tools parallel
    
    ENROOT_VERSION=3.4.1
    wget https://github.com/NVIDIA/enroot/releases/download/v${ENROOT_VERSION}/enroot-${ENROOT_VERSION}-1.el7.x86_64.rpm
    wget https://github.com/NVIDIA/enroot/releases/download/v${ENROOT_VERSION}/enroot+caps-${ENROOT_VERSION}-1.el7.x86_64.rpm
    
    sudo rpm -ivh enroot-${ENROOT_VERSION}-1.el7.x86_64.rpm
    sudo rpm -ivh enroot+caps-${ENROOT_VERSION}-1.el7.x86_64.rpm
    
    rm -f enroot*.rpm
fi

# 6. DLCë¥¼ Enroot í˜•ì‹ìœ¼ë¡œ ë³€í™˜
echo "Converting DLC to Enroot format..."
mkdir -p /fsx/containers

# ECR ì¸ì¦ ì„¤ì •
aws ecr get-login-password --region $AWS_REGION | \
    enroot-credentials set \
    --username AWS \
    --password-stdin \
    763104351884.dkr.ecr.$AWS_REGION.amazonaws.com

# Enrootë¡œ import
enroot import \
    --output /fsx/containers/${DLC_FRAMEWORK}-${DLC_VERSION}.sqsh \
    docker://$DLC_IMAGE

echo "DLC setup completed!"
echo "Container image: /fsx/containers/${DLC_FRAMEWORK}-${DLC_VERSION}.sqsh"

# 7. ê²€ì¦
echo "Verifying installation..."
docker run --rm --gpus all $DLC_IMAGE nvidia-smi

ðŸ—ï¸ ë°©ë²• 2: Custom AMI (ìµœê³  ì„±ëŠ¥) â­â­â­â­â­
2-1. Custom AMI ë¹Œë“œ
#!/bin/bash
# scripts/build_dlc_ami.sh

set -e

echo "=== Building Custom ParallelCluster AMI with DLC ==="

# 1. ParallelCluster ê¸°ë³¸ AMIë¡œ ì¸ìŠ¤í„´ìŠ¤ ì‹œìž‘
BASE_AMI="ami-0abcdef1234567890"  # ParallelCluster ê¸°ë³¸ AMI
INSTANCE_TYPE="p4d.24xlarge"

# ì¸ìŠ¤í„´ìŠ¤ ì‹œìž‘
INSTANCE_ID=$(aws ec2 run-instances \
    --image-id $BASE_AMI \
    --instance-type $INSTANCE_TYPE \
    --key-name my-keypair \
    --subnet-id subnet-12345678 \
    --security-group-ids sg-12345678 \
    --iam-instance-profile Name=ParallelClusterInstanceProfile \
    --block-device-mappings '[{"DeviceName":"/dev/xvda","Ebs":{"VolumeSize":500,"VolumeType":"gp3"}}]' \
    --query 'Instances[0].InstanceId' \
    --output text)

echo "Instance started: $INSTANCE_ID"
echo "Waiting for instance to be running..."
aws ec2 wait instance-running --instance-ids $INSTANCE_ID

# ì¸ìŠ¤í„´ìŠ¤ IP ê°€ì ¸ì˜¤ê¸°
INSTANCE_IP=$(aws ec2 describe-instances \
    --instance-ids $INSTANCE_ID \
    --query 'Reservations[0].Instances[0].PublicIpAddress' \
    --output text)

echo "Instance IP: $INSTANCE_IP"
echo "Waiting for SSH to be ready..."
sleep 60

# 2. ì„¤ì • ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰
cat > /tmp/setup_ami.sh << 'EOF'
#!/bin/bash
set -e

echo "=== Configuring AMI with DLC ==="

# Docker ì„¤ì¹˜
sudo yum update -y
sudo yum install -y docker
sudo systemctl start docker
sudo systemctl enable docker
sudo usermod -aG docker ec2-user

# NVIDIA Container Toolkit
distribution=$(. /etc/os-release;echo $ID$VERSION_ID)
curl -s -L https://nvidia.github.io/libnvidia-container/$distribution/libnvidia-container.repo | \
    sudo tee /etc/yum.repos.d/nvidia-container-toolkit.repo
sudo yum install -y nvidia-container-toolkit
sudo nvidia-ctk runtime configure --runtime=docker
sudo systemctl restart docker

# Enroot & Pyxis ì„¤ì¹˜
sudo yum install -y jq squashfs-tools parallel

ENROOT_VERSION=3.4.1
wget https://github.com/NVIDIA/enroot/releases/download/v${ENROOT_VERSION}/enroot-${ENROOT_VERSION}-1.el7.x86_64.rpm
wget https://github.com/NVIDIA/enroot/releases/download/v${ENROOT_VERSION}/enroot+caps-${ENROOT_VERSION}-1.el7.x86_64.rpm
sudo rpm -ivh enroot-${ENROOT_VERSION}-1.el7.x86_64.rpm
sudo rpm -ivh enroot+caps-${ENROOT_VERSION}-1.el7.x86_64.rpm

# Pyxis ì„¤ì¹˜
PYXIS_VERSION=0.19.0
wget https://github.com/NVIDIA/pyxis/archive/refs/tags/v${PYXIS_VERSION}.tar.gz
tar xf v${PYXIS_VERSION}.tar.gz
cd pyxis-${PYXIS_VERSION}
sudo make install
sudo mkdir -p /etc/slurm/plugstack.conf.d
echo "required /usr/local/lib/slurm/spank_pyxis.so" | sudo tee /etc/slurm/plugstack.conf.d/pyxis.conf

# DLC ì´ë¯¸ì§€ ë¯¸ë¦¬ ë‹¤ìš´ë¡œë“œ (ì„ íƒì )
AWS_REGION=$(ec2-metadata --availability-zone | sed 's/placement: \(.*\).$/\1/')

# ECR ë¡œê·¸ì¸
aws ecr get-login-password --region $AWS_REGION | \
    docker login --username AWS --password-stdin \
    763104351884.dkr.ecr.$AWS_REGION.amazonaws.com

# ì£¼ìš” DLC ì´ë¯¸ì§€ Pull
for framework in pytorch tensorflow; do
    echo "Pulling $framework DLC..."
    docker pull 763104351884.dkr.ecr.$AWS_REGION.amazonaws.com/${framework}-training:2.1.0-gpu-py310-cu118-ubuntu20.04
done

echo "AMI setup completed!"
EOF

# ìŠ¤í¬ë¦½íŠ¸ ì „ì†¡ ë° ì‹¤í–‰
scp -i ~/.ssh/my-keypair.pem /tmp/setup_ami.sh ec2-user@$INSTANCE_IP:/tmp/
ssh -i ~/.ssh/my-keypair.pem ec2-user@$INSTANCE_IP 'bash /tmp/setup_ami.sh'

# 3. AMI ìƒì„±
echo "Creating AMI..."
AMI_NAME="parallelcluster-dlc-$(date +%Y%m%d-%H%M%S)"
AMI_ID=$(aws ec2 create-image \
    --instance-id $INSTANCE_ID \
    --name $AMI_NAME \
    --description "ParallelCluster with DLC pre-installed" \
    --query 'ImageId' \
    --output text)

echo "AMI created: $AMI_ID"
echo "Waiting for AMI to be available..."
aws ec2 wait image-available --image-ids $AMI_ID

# 4. ì¸ìŠ¤í„´ìŠ¤ ì¢…ë£Œ
aws ec2 terminate-instances --instance-ids $INSTANCE_ID

echo "=== Custom AMI Build Complete ==="
echo "AMI ID: $AMI_ID"
echo "Use this AMI in your ParallelCluster config"

2-2. Custom AMI ì‚¬ìš©
# config-with-custom-ami.yaml
Region: us-east-1

Image:
  Os: alinux2
  CustomAmi: ami-0abc123def456789  # ìœ„ì—ì„œ ìƒì„±í•œ Custom AMI

HeadNode:
  InstanceType: c5.4xlarge
  Networking:
    SubnetId: subnet-12345678

Scheduling:
  Scheduler: slurm
  SlurmQueues:
    - Name: compute
      ComputeResources:
        - Name: gpu-nodes
          InstanceType: p4d.24xlarge
          MinCount: 0
          MaxCount: 100
          Efa:
            Enabled: true
      
      Networking:
        SubnetIds:
          - subnet-12345678

SharedStorage:
  - MountDir: /fsx
    Name: fsx-storage
    StorageType: FsxLustre
    FsxLustreSettings:
      StorageCapacity: 1200

ðŸš€ ë°©ë²• 3: Enroot/Pyxis + DLC (ê¶Œìž¥) â­â­â­â­â­
3-1. ParallelCluster ì„¤ì • (Enroot/Pyxis í¬í•¨)
# config-enroot-dlc.yaml
Region: us-east-1
Image:
  Os: alinux2

HeadNode:
  InstanceType: c5.4xlarge
  Networking:
    SubnetId: subnet-12345678
  Iam:
    AdditionalIamPolicies:
      - Policy: arn:aws:iam::aws:policy/AmazonEC2ContainerRegistryReadOnly
  CustomActions:
    OnNodeConfigured:
      Script: s3://my-bucket/scripts/setup_enroot_pyxis.sh

Scheduling:
  Scheduler: slurm
  SlurmQueues:
    - Name: compute
      ComputeResources:
        - Name: gpu-nodes
          InstanceType: p4d.24xlarge
          MinCount: 0
          MaxCount: 100
          Efa:
            Enabled: true
      
      CustomActions:
        OnNodeConfigured:
          Script: s3://my-bucket/scripts/setup_enroot_pyxis.sh
      
      Iam:
        AdditionalIamPolicies:
          - Policy: arn:aws:iam::aws:policy/AmazonEC2ContainerRegistryReadOnly

SharedStorage:
  - MountDir: /fsx
    Name: fsx-storage
    StorageType: FsxLustre
    FsxLustreSettings:
      StorageCapacity: 1200
      ImportPath: s3://my-bucket/containers  # DLC ì»¨í…Œì´ë„ˆ ì €ìž¥

3-2. Enroot/Pyxis ì„¤ì¹˜ ìŠ¤í¬ë¦½íŠ¸
#!/bin/bash
# scripts/setup_enroot_pyxis.sh

set -e

NODE_TYPE=$(cat /etc/parallelcluster/cfnconfig | jq -r '.cfn_node_type')
echo "=== Setting up Enroot/Pyxis on $NODE_TYPE ==="

# 1. ì˜ì¡´ì„± ì„¤ì¹˜
sudo yum install -y jq squashfs-tools parallel fuse-overlayfs

# 2. Enroot ì„¤ì¹˜
ENROOT_VERSION=3.4.1

if ! command -v enroot &> /dev/null; then
    echo "Installing Enroot..."
    wget https://github.com/NVIDIA/enroot/releases/download/v${ENROOT_VERSION}/enroot-${ENROOT_VERSION}-1.el7.x86_64.rpm
    wget https://github.com/NVIDIA/enroot/releases/download/v${ENROOT_VERSION}/enroot+caps-${ENROOT_VERSION}-1.el7.x86_64.rpm
    
    sudo rpm -ivh enroot-${ENROOT_VERSION}-1.el7.x86_64.rpm
    sudo rpm -ivh enroot+caps-${ENROOT_VERSION}-1.el7.x86_64.rpm
    
    rm -f enroot*.rpm
fi

# 3. Enroot ì„¤ì •
sudo mkdir -p /etc/enroot
cat << 'EOF' | sudo tee /etc/enroot/enroot.conf
ENROOT_RUNTIME_PATH /run/enroot/user-$(id -u)
ENROOT_CACHE_PATH /fsx/enroot-cache
ENROOT_DATA_PATH /fsx/enroot-data
ENROOT_TEMP_PATH ${TMPDIR:-/tmp}
EOF

# 4. Pyxis ì„¤ì¹˜ (ì»´í“¨íŠ¸ ë…¸ë“œë§Œ)
if [ "$NODE_TYPE" == "ComputeFleet" ]; then
    PYXIS_VERSION=0.19.0
    
    if [ ! -f /usr/local/lib/slurm/spank_pyxis.so ]; then
        echo "Installing Pyxis..."
        wget https://github.com/NVIDIA/pyxis/archive/refs/tags/v${PYXIS_VERSION}.tar.gz
        tar xf v${PYXIS_VERSION}.tar.gz
        cd pyxis-${PYXIS_VERSION}
        sudo make install
        cd ..
        rm -rf pyxis-${PYXIS_VERSION} v${PYXIS_VERSION}.tar.gz
    fi
    
    # Pyxis ì„¤ì •
    sudo mkdir -p /etc/slurm/plugstack.conf.d
    echo "required /usr/local/lib/slurm/spank_pyxis.so" | \
        sudo tee /etc/slurm/plugstack.conf.d/pyxis.conf
fi

# 5. ECR ì¸ì¦ ì„¤ì •
AWS_REGION=$(ec2-metadata --availability-zone | sed 's/placement: \(.*\).$/\1/')

mkdir -p ~/.config/enroot
aws ecr get-login-password --region $AWS_REGION | \
    enroot-credentials set \
    --username AWS \
    --password-stdin \
    763104351884.dkr.ecr.$AWS_REGION.amazonaws.com

echo "Enroot/Pyxis setup completed!"

3-3. DLC ì´ë¯¸ì§€ ì¤€ë¹„ ìŠ¤í¬ë¦½íŠ¸
#!/bin/bash
# scripts/prepare_dlc_containers.sh
# í—¤ë“œ ë…¸ë“œì—ì„œ í•œ ë²ˆë§Œ ì‹¤í–‰

set -e

AWS_REGION=$(aws configure get region)
DLC_REGISTRY="763104351884.dkr.ecr.$AWS_REGION.amazonaws.com"

# ECR ë¡œê·¸ì¸
aws ecr get-login-password --region $AWS_REGION | \
    enroot-credentials set \
    --username AWS \
    --password-stdin \
    $DLC_REGISTRY

# ì»¨í…Œì´ë„ˆ ë””ë ‰í† ë¦¬ ìƒì„±
mkdir -p /fsx/containers/dlc

# DLC ì´ë¯¸ì§€ ëª©ë¡
declare -A DLC_IMAGES=(
    ["pytorch-2.1"]="pytorch-training:2.1.0-gpu-py310-cu118-ubuntu20.04"
    ["pytorch-2.0"]="pytorch-training:2.0.1-gpu-py310-cu118-ubuntu20.04"
    ["tensorflow-2.13"]="tensorflow-training:2.13.0-gpu-py310-cu118-ubuntu20.04"
    ["mxnet-1.9"]="mxnet-training:1.9.0-gpu-py38-cu112-ubuntu20.04"
)

# ê° DLC ì´ë¯¸ì§€ë¥¼ Enroot í˜•ì‹ìœ¼ë¡œ ë³€í™˜
for name in "${!DLC_IMAGES[@]}"; do
    image="${DLC_IMAGES[$name]}"
    echo "=== Processing $name ==="
    
    enroot import \
        --output /fsx/containers/dlc/${name}.sqsh \
        docker://${DLC_REGISTRY}/${image}
    
    echo "âœ“ Created /fsx/containers/dlc/${name}.sqsh"
done

echo ""
echo "=== DLC Containers Ready ==="
ls -lh /fsx/containers/dlc/

ðŸŽ¯ ì‹¤ì œ ì‚¬ìš© ì˜ˆì œ
DLCë¡œ í•™ìŠµ ì‹¤í–‰
#!/bin/bash
# scripts/train_with_dlc.sh

#SBATCH --job-name=dlc-pytorch-training
#SBATCH --partition=compute
#SBATCH --nodes=4
#SBATCH --ntasks-per-node=8
#SBATCH --gpus-per-node=8
#SBATCH --exclusive
#SBATCH --output=logs/%x_%j.out

# DLC ì»¨í…Œì´ë„ˆ ì§€ì •
declare -a CONTAINER_ARGS=(
    --container-image=/fsx/containers/dlc/pytorch-2.1.sqsh
    --container-mounts=/fsx:/fsx
)

# Torchrun ì„¤ì •
declare -a TORCHRUN_ARGS=(
    --nproc_per_node=8
    --nnodes=$SLURM_JOB_NUM_NODES
    --rdzv_id=$SLURM_JOB_ID
    --rdzv_backend=c10d
    --rdzv_endpoint=$(scontrol show hostname $SLURM_NODELIST | head -n1)
)

# DLC ì»¨í…Œì´ë„ˆë¡œ í•™ìŠµ ì‹¤í–‰
srun -l "${CONTAINER_ARGS[@]}" \
    torchrun "${TORCHRUN_ARGS[@]}" \
    /fsx/training/train.py \
    --data-path /fsx/data \
    --output-dir /fsx/checkpoints \
    --epochs 100

ì—¬ëŸ¬ DLC ë²„ì „ ë™ì‹œ ì‹¤í–‰
#!/bin/bash
# scripts/multi_dlc_training.sh

# PyTorch 2.1ë¡œ ì‹¤í—˜ 1
sbatch --job-name=exp1-pt21 \
    --export=DLC_IMAGE=/fsx/containers/dlc/pytorch-2.1.sqsh \
    scripts/train_template.sh

# PyTorch 2.0ë¡œ ì‹¤í—˜ 2
sbatch --job-name=exp2-pt20 \
    --export=DLC_IMAGE=/fsx/containers/dlc/pytorch-2.0.sqsh \
    scripts/train_template.sh

# TensorFlowë¡œ ì‹¤í—˜ 3
sbatch --job-name=exp3-tf \
    --export=DLC_IMAGE=/fsx/containers/dlc/tensorflow-2.13.sqsh \
    scripts/train_template.sh

ðŸ“Š ë°©ë²•ë³„ ìž¥ë‹¨ì  ìš”ì•½
OnNodeConfigured ìŠ¤í¬ë¦½íŠ¸
ìž¥ì :
âœ… ì„¤ì • ê°„ë‹¨
âœ… ë™ì  ì—…ë°ì´íŠ¸ ê°€ëŠ¥
âœ… ë²„ì „ ê´€ë¦¬ ì‰¬ì›€

ë‹¨ì :
âŒ ë…¸ë“œ ì‹œìž‘ ì‹œê°„ ì¦ê°€ (5-10ë¶„)
âŒ ë„¤íŠ¸ì›Œí¬ ì˜ì¡´ì„±
âŒ ìŠ¤ì¼€ì¼ë§ ì‹œ ë°˜ë³µ ë‹¤ìš´ë¡œë“œ

Custom AMI
ìž¥ì :
âœ… ê°€ìž¥ ë¹ ë¥¸ ë…¸ë“œ ì‹œìž‘ (<2ë¶„)
âœ… ë„¤íŠ¸ì›Œí¬ ë…ë¦½ì 
âœ… ì¼ê´€ëœ í™˜ê²½

ë‹¨ì :
âŒ AMI ë¹Œë“œ ë³µìž¡
âŒ ì—…ë°ì´íŠ¸ ì‹œ ìž¬ë¹Œë“œ í•„ìš”
âŒ ë¦¬ì „ë³„ë¡œ AMI ë³µì‚¬ í•„ìš”

Enroot/Pyxis + DLC (ê¶Œìž¥)
ìž¥ì :
âœ… HPC í™˜ê²½ ìµœì í™”
âœ… ë¹ ë¥¸ ì»¨í…Œì´ë„ˆ ì‹œìž‘
âœ… ì—¬ëŸ¬ ë²„ì „ ë™ì‹œ ì‚¬ìš©
âœ… FSx ìºì‹±ìœ¼ë¡œ ë¹ ë¥¸ ë¡œë“œ
âœ… Slurm ì™„ë²½ í†µí•©

ë‹¨ì :
âŒ ì´ˆê¸° ì„¤ì • ë³µìž¡
âŒ Enroot/Pyxis í•™ìŠµ í•„ìš”

ðŸŽ“ ìµœì¢… ê¶Œìž¥ì‚¬í•­
ë‹¹ì‹ ì˜ ê²½ìš° (100ê°œ ODCR, ë‹¤ì¤‘ í”„ë ˆìž„ì›Œí¬)

ê¶Œìž¥: Enroot/Pyxis + DLC â­â­â­â­â­

ì´ìœ :

    FSx ê³µìœ  ìŠ¤í† ë¦¬ì§€ í™œìš© - DLC ì»¨í…Œì´ë„ˆë¥¼ FSxì— í•œ ë²ˆë§Œ ì €ìž¥ - ëª¨ë“  ë…¸ë“œê°€ ë¹ ë¥´ê²Œ ì ‘ê·¼

    ì—¬ëŸ¬ DLC ë²„ì „ ë™ì‹œ ì‚¬ìš© - PyTorch 2.1, 2.0, TensorFlow ë“± - ìž‘ì—…ë³„ë¡œ ë‹¤ë¥¸ ì»¨í…Œì´ë„ˆ ì„ íƒ

    ë¹ ë¥¸ ìŠ¤ì¼€ì¼ë§ - ë…¸ë“œ ì‹œìž‘ ì‹œ ë‹¤ìš´ë¡œë“œ ë¶ˆí•„ìš” - FSxì—ì„œ ì§ì ‘ ë§ˆìš´íŠ¸ (ì´ˆ ë‹¨ìœ„)

    Slurm ì™„ë²½ í†µí•© - --container-image ì˜µì…˜ìœ¼ë¡œ ê°„ë‹¨ ì‚¬ìš© - QoS, Accounting ëª¨ë‘ ì§€ì›

êµ¬í˜„ ìˆœì„œ
1. ParallelCluster ìƒì„± (Enroot/Pyxis í¬í•¨) â””â”€ OnNodeConfiguredë¡œ Enroot/Pyxis ì„¤ì¹˜

2. í—¤ë“œ ë…¸ë“œì—ì„œ DLC ì¤€ë¹„

Advanced
Connected
